---
title: "UKB KDSC Cohort"
format: html
---

# 2. Cohort Construction for CKD Staging
We construct a cohort for KDIGO-based CKD staging. We need:
 - eid, sex, date_of_birth (for eGFR calculation)
 - Assessment date (baseline)
 - GP linkage status
 - Censoring dates (start and end of follow-up)
 - Death status

We read pre-extracted CSV data from data/common/. These can be either:
 - Generated by R01-extract.rmd, or
 - Copied from the parent repo: `cp -r ../data/common/ data/common/`

## 0. Setup
```{r}
source(knitr::purl("R00-parameters.rmd", quiet = TRUE, output = tempfile()))

library(tidyverse)
library(data.table)
library(dtplyr)
library(arrow)
```

## 1. Data Sources
```{r}
dt_demo <- fread("data/extracted/demographics.csv")
dt_gp_regs <- fread("data/extracted/gp_registrations.csv")
dt_followup <- fread("data/extracted/follow_up.csv")
```

## 2. Prepare
### 2.1 Demographics
```{r}
dt_cohort <- dt_demo %>%
  lazy_dt() %>%
  filter(visit_index == 0) %>%
  mutate(sex = as.factor(sex)) %>%
  select(
    eid,
    date_of_birth = approx_birth_date, sex,
    assessment_nation, assessment_date
  ) %>%
  as.data.table()
```

### 2.2 GP Linkage
Determine which participants have linked GP records from the registration table.
```{r}
gp_linked_eids <- dt_gp_regs[, unique(eid)]

dt_cohort[, has_gp := eid %in% gp_linked_eids]
```

## 3. Visits Table
```{r}
dt_visits <- dt_demo %>%
  lazy_dt() %>%
  filter(eid %in% dt_cohort$eid) %>%
  select(eid, visit_index, assessment_date) %>%
  arrange(eid, assessment_date) %>%
  as.data.table()

# Remove duplicate visit dates
duplicate_visits <- dt_visits[, .(n = .N), by = .(eid, assessment_date)][n > 1, unique(eid)]
dt_visits <- dt_visits[!(eid %in% duplicate_visits & visit_index != 0)]
```

## 4. Augment Cohort with Follow-up Dates
```{r}
baseline_dates <- dt_visits %>%
  lazy_dt() %>%
  filter(visit_index == 0) %>%
  select(eid, baseline_date = assessment_date) %>%
  as.data.table()

followup_dates <- dt_followup %>%
  lazy_dt() %>%
  mutate(censor_ehr = pmax(max_hospital_censor, max_gp_censor, na.rm = TRUE)) %>%
  mutate(censor_date_end = pmin(max_death_censor, censor_ehr, na.rm = TRUE)) %>%
  select(eid, censor_date_end, has_died) %>%
  as.data.table()

dt_cohort <- dt_cohort %>%
  lazy_dt() %>%
  inner_join(baseline_dates, by = "eid") %>%
  inner_join(followup_dates, by = "eid") %>%
  mutate(censor_date_start = baseline_date) %>%
  filter(!is.na(censor_date_start) & !is.na(censor_date_end)) %>%
  as.data.table()
```

## 5. Validation
```{r}
stopifnot("No duplicate eids" = dt_cohort[, .N, by = eid][N > 1, .N] == 0)
stopifnot("All participants have baseline_date" = dt_cohort[is.na(baseline_date), .N] == 0)
stopifnot("All participants have censor_date_start" = dt_cohort[is.na(censor_date_start), .N] == 0)
stopifnot("All participants have censor_date_end" = dt_cohort[is.na(censor_date_end), .N] == 0)
stopifnot("censor_date_start <= censor_date_end" = dt_cohort[censor_date_start > censor_date_end, .N] == 0)
```

## 6. Save
```{r}
dt_cohort_out <- dt_cohort[, .(eid, date_of_birth, sex, has_gp, baseline_date, censor_date_start, censor_date_end, has_died)]

out_file <- "data/cohort.parquet"
dir.create(dirname(out_file), showWarnings = FALSE, recursive = TRUE)
write_parquet(dt_cohort_out, out_file)
upload_to_dx(out_file, "ukb-kdsc-staging/cohort.parquet")

out_file <- "data/visits.parquet"
write_parquet(dt_visits, out_file)
upload_to_dx(out_file, "ukb-kdsc-staging/visits.parquet")

cat(sprintf("Cohort: %d individuals\n", nrow(dt_cohort_out)))
cat(sprintf("GP-linked: %d\n", sum(dt_cohort_out$has_gp)))
cat(sprintf("Deaths: %d\n", sum(dt_cohort_out$has_died)))
cat(sprintf("Median follow-up: %.1f years\n", median(as.numeric(dt_cohort_out$censor_date_end - dt_cohort_out$censor_date_start) / 365.25)))
```
